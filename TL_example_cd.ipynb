{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image data we use for training\n",
    "# https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data?select=train.zip\n",
    "# (could use !wget ...)\n",
    "\n",
    "# For image files, Keras will automatically assign the name of the class (category) based on its parent folder name\n",
    "# After downloading the data and moving them to the project directory, execute in the terminal:\n",
    "!unzip train.zip\n",
    "%mv train data\n",
    "%cd data\n",
    "%mkdir train val\n",
    "%mkdir train/cat train/dog\n",
    "%mkdir val/cat val/dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select randomly 250 images per class and place them into train and val folders\n",
    "%ls | grep cat | sort -R | head -250 | xargs -I {} mv {} train/cat/\n",
    "%ls | grep dog | sort -R | head -250 | xargs -I {} mv {} train/dog/\n",
    "%ls | grep cat | sort -R | head -250 | xargs -I {} mv {} val/cat/\n",
    "%ls | grep dog | sort -R | head -250 | xargs -I {} mv {} val/dog/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge tensorflow --yes\n",
    "!conda install -c conda-forge keras --yes\n",
    "!conda install -c conda-forge pillow --yes\n",
    "!conda install -c conda-forge matplotlib --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "# We treat this problem as a multiclass problem, i.e. \"cats vs dogs\" (Number of classes 2)\n",
    "TRAIN_DATA_DIR = 'data/train/'\n",
    "VALIDATION_DATA_DIR = 'data/valid/'\n",
    "TRAIN_SAMPLES = 500\n",
    "VALIDATION_SAMPLES = 500\n",
    "NUM_CLASSES = 2\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification\n",
    "\n",
    "- Input data are understood by DL algorithms as **tensors** (multidimensional array or list)\n",
    "\n",
    "- Image data: \n",
    "    \n",
    "    - Input batch of images \n",
    "\n",
    "    - 4D tensor:\n",
    "\n",
    "<img src=\"Pictures/4_axis_tensor.png\" style=\"width: 15%\"/>\n",
    "\n",
    "\n",
    "*https://www.tensorflow.org/guide/tensor*\n",
    "\n",
    "- Images: 2 dimensions define Pixel values, 3rd RGB values, 4th number of images per batch\n",
    "\n",
    "- In our case: $224*224*3*64$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   zoom_range=0.2)\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# ?ImageDataGenerator\n",
    "# Generates batches of image data with real-time data augmentation\n",
    "# Loops over the data in batches\n",
    "# ImageDataGenerator is a function provided by keras for augmenting the data while they are loaded\n",
    "# preprocess_input: scale pixel values (0-255) of rgb channels to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images are combined into batches, training single images is inefficient\n",
    "# Shuffling to introduce more randomness\n",
    "# Seed for reproducibility\n",
    "train_generator = train_datagen.flow_from_directory(TRAIN_DATA_DIR,\n",
    "                                                    target_size=(IMG_WIDTH,\n",
    "                                                                 IMG_HEIGHT),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=12345,\n",
    "                                                    class_mode='categorical')\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    VALIDATION_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "# include_top = FALSE: Throw away last few specific layers (fully connected layers)\n",
    "def model_maker():\n",
    "    base_model = MobileNet(include_top=False, input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False # freeze the layers\n",
    "    input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3)) # instantiate a Keras tensor\n",
    "    custom_model = base_model(input)\n",
    "    custom_model = GlobalAveragePooling2D()(custom_model)\n",
    "    custom_model = Dense(64, activation = 'relu')(custom_model)\n",
    "    custom_model = Dropout(0.5)(custom_model)\n",
    "    predictions = Dense(NUM_CLASSES, activation='softmax')(custom_model)\n",
    "    return Model(inputs=input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_maker()\n",
    "# model.summary()\n",
    "\n",
    "# Information on MobileNet and its arguments:\n",
    "# https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/README.md\n",
    "# ?MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training (i.e. model fitting)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(0.001), \n",
    "              metrics=['acc'])\n",
    "model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=math.ceil(float(TRAIN_SAMPLES)/BATCH_SIZE), \n",
    "    epochs=10, # epoch -> one full training step (network goes over entire dataset)\n",
    "    validation_data=validation_generator, \n",
    "    validation_steps=math.ceil(float(VALIDATION_SAMPLES) / BATCH_SIZE)) \n",
    "# Google colab can be used for running on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_cd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model on a sample image\n",
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "model = load_model('model_cd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample picture and check how the model performs\n",
    "img_path = 'Pictures/sample_dog.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "display(img)\n",
    "img_array = image.img_to_array(img)\n",
    "expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "preprocessed_img = expanded_img_array / 255.  # Preprocess the image\n",
    "\n",
    "# prediction > 0.5\n",
    "# How does NN arrive at probabilities?\n",
    "prediction = model.predict(preprocessed_img)\n",
    "print(prediction)\n",
    "print(validation_generator.class_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
