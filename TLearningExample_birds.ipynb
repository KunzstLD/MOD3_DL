{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning using a CNN\n",
    "\n",
    "Using the bird species classification dataset from kaggle: \n",
    "https://www.kaggle.com/gpiosenka/100-bird-species\n",
    " \n",
    "\n",
    "#### Steps: \n",
    "\n",
    "1) Organisation: Download labelled images and divide into training and validation folders\n",
    "\n",
    "2) Data pipeline: Reading data, preprocessing, grouping multiple images into batches\n",
    "   \n",
    "3) Data augmentation: Small changes like rotation, zooming etc. to increase variation in training data\n",
    "\n",
    "4) Model definition\n",
    "\n",
    "5) Training & testing\n",
    "\n",
    "6) Save the model for a potential application "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D, MaxPooling2D,Conv2D\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "# We treat this problem as a multiclass problem, i.e. \"cats vs dogs\" (Number of classes 2)\n",
    "TRAIN_DATA_DIR = 'data_bird_excerpt/train/'\n",
    "VALIDATION_DATA_DIR = 'data_bird_excerpt/valid/'\n",
    "NUM_CLASSES = 10\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(TRAIN_DATA_DIR))\n",
    "# help(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying images\n",
    "img_path = 'data_bird_excerpt/train/AFRICAN FIREFINCH/001.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224)) \n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the image \n",
    "img_array = image.img_to_array(img)\n",
    "expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "expanded_img_array\n",
    "expanded_img_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification\n",
    "\n",
    "- Input data are understood by DL algorithms as **tensors** (multidimensional array or list)\n",
    "\n",
    "- Image data: \n",
    "    \n",
    "    - Input batch of images \n",
    "\n",
    "    - 4D tensor:\n",
    "\n",
    "<img src=\"Pictures/4_axis_tensor.png\" style=\"width: 15%\"/>\n",
    "\n",
    "\n",
    "*https://www.tensorflow.org/guide/tensor*\n",
    "\n",
    "- Images: 2 dimensions define Pixel values, 3rd RGB values, 4th number of images per batch\n",
    "\n",
    "- In our case: $224*224*3*32$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   zoom_range=0.2)\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Generates batches of image data with real-time data augmentation\n",
    "# Loops over the data in batches\n",
    "# ImageDataGenerator is a function provided by keras for augmenting the data while they are loaded\n",
    "# preprocess_input: scale pixel values (0-255) of rgb channels to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images are combined into batches, training single images is inefficient\n",
    "# Shuffling to introduce more randomness\n",
    "# Seed for reproducibility\n",
    "train_generator = train_datagen.flow_from_directory(TRAIN_DATA_DIR,\n",
    "                                                    target_size=(IMG_WIDTH,\n",
    "                                                                 IMG_HEIGHT),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=12345,\n",
    "                                                    class_mode='categorical')\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    VALIDATION_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple ANN\n",
    "ann_model = Sequential()\n",
    "ann_model.add(Flatten(input_shape = (224,224,3))) # transform tensors to single array (i.e. to 1D)\n",
    "ann_model.add(Dense(300, activation = 'relu'))\n",
    "ann_model.add(Dense(100, activation = 'relu'))\n",
    "ann_model.add(Dense(NUM_CLASSES, activation = 'sigmoid'))\n",
    "\n",
    "# Configure and train the model\n",
    "ann_model.compile(optimizer='adam', loss='categorical_crossentropy', \n",
    "              metrics=['acc'])\n",
    "\n",
    "ann_model.fit(\n",
    "    train_generator, \n",
    "    epochs = 5, # epoch -> one full training step (network goes over entire dataset)\n",
    "    validation_data=validation_generator, \n",
    "   ) \n",
    "# model.fit(x_train.values,y_train.values, validation_data=\n",
    "# (x_val,y_val),epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: \n",
    "- Create and fit a simple CNN with:\n",
    "    - Convolutional layer, MaxPooling2D, Convolutional Layer, MaxPooling2D, Flatten, 2 Dense layers\n",
    "    - Use Relu as activation function, a 3*3 Kernel, 32 filters for the first convolutional layer, and 64 kernels for the second convolutional layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning Model definition\n",
    "# include_top = FALSE: Throw away last few specific layers (fully connected layers)\n",
    "def model_maker():\n",
    "    base_model = MobileNet(include_top=False, input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False # freeze the layers\n",
    "    input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3)) # instantiate a Keras tensor\n",
    "    custom_model = base_model(input)\n",
    "    custom_model = GlobalAveragePooling2D()(custom_model) # downsizing \n",
    "    custom_model = Dense(64, activation = 'relu')(custom_model)\n",
    "    custom_model = Dropout(0.2)(custom_model)\n",
    "    predictions = Dense(NUM_CLASSES, activation='softmax')(custom_model)\n",
    "    return Model(inputs=input, outputs=predictions)\n",
    "\n",
    "    # softmax normalises probabilities \n",
    "    # Example for two classes:\n",
    "    # sigmoid: 0.5, 0.6.\n",
    "    # softmax: 0.5 / (0.5 + 0.6), 0.6/ (0.5 + 0.6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_maker()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on MobileNet and its arguments:\n",
    "# https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/README.md\n",
    "# Paper: https://arxiv.org/pdf/1704.04861.pdf\n",
    "\n",
    "# Example code to check the layers in MobildeNet() and how many of them are trainable:\n",
    "base_model_test = MobileNet(include_top=True, input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "# all layers\n",
    "for i, layer in enumerate(base_model_test.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# trainable\n",
    "# for i,layer in enumerate(base_model_test.layers[:]):\n",
    "#   print(i,layer.name,layer.trainable)\n",
    "# Use ':' (slice) to change the number of trainable layers \n",
    "# e.g. for layer in base_model_test.layers[:5]:\n",
    "#   layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training \n",
    "# loss - categorical crossentropy: for feedback to the model\n",
    "# metric - for reporting \n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(0.001), \n",
    "              metrics=['acc'])\n",
    "model.fit(\n",
    "    train_generator, \n",
    "    epochs = 5,\n",
    "    validation_data=validation_generator, \n",
    "   ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "\n",
    "- Why there are 40 steps during each epoch?\n",
    "- Can you spot any potential problems with the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model architecture, weights & training configuration\n",
    "# see also: https://www.tensorflow.org/tutorials/keras/save_and_load\n",
    "model.save('model_bird10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model on a sample image\n",
    "# Load sample picture and check how the model performs\n",
    "# img_path = 'data_bird_excerpt/images to test/14.jpg'\n",
    "# img_path = 'data_bird_excerpt/images to test/sample_dog.jpeg'\n",
    "img_path = 'data_bird_excerpt/images to test/european_greenfinch.jpg'\n",
    "\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "preprocessed_img = expanded_img_array / 255.  # Preprocess the image\n",
    "prediction = model.predict(preprocessed_img)\n",
    "print(prediction.round(3))\n",
    "print(validation_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the results\n",
    "\n",
    "### Important questions to ask: \n",
    "1. Which images is the model most confident about?\n",
    "\n",
    "2. Which least confident?\n",
    "\n",
    "3. Which images have incorrect predictions despite of having highly confident predictions from the model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to do to improve model accuracy?\n",
    "\n",
    "- Acquire more training data\n",
    "\n",
    "- Revise training data (wrong labels, images that show not the desired categories, items covering parts of the classified animals)\n",
    "\n",
    "- Reasons for mispredictions: \n",
    "    - Too low or too high illumination\n",
    "    - Size \n",
    "    - Difficult-to-distinguish backgrounds \n",
    "\n",
    "- Improve hyperparameters of the deep learning model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
